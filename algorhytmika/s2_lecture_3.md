# Лекция 3

## Сортировка перемешиванием (двунаправленная "пузырьковая" сортировка)

При сортирвке методом "пузырька" при первом проходе максимальный элемент массива перемещается в самый его конец. После второго прохода на предпоследнем месте окажется второй по величине элемент массива, и т.д.

Таким образом, каждый раз остается только отсортировать (тем же способом) оставшуюся часть массива (без элементов массива в его конце, уже находящихся на "своих" местах).

Тут важно на каждом новом проходе уменьшать на 1 величину верхнего предела переменного индекса массива с тем, чтобы не выполнять бесполезных сравнений в уже отсортированной части массива.

Но можно таже, сделав проход по массиву слева направо, в результате которого наибольший элемент переместится в его конец, сделать затем аналогичный проход справа налево, в результате которого наименьший элемент переместился бы в начало. Таким образом, чередуя проходы "слева направо" с проходами "справа налево", можно будет уменьшать оставшуюся неотсортированной часть массива сразу с двух сторон.

Такую модификацию "пузырьковой" сортировки назвают сортировкой "перемешиванием", или "шейкерной" сортировкой.

Реализация этого алгоритма может быть следующей.

```julia
function mixersort!(a)
    i_beg = 1
    i_end = length(a)
    while i_beg < i_end
        @inbounds for i in i_beg:i_end-1 # макрос @inbounds отменяет контроль выхода за пределы массива
            if a[i] > a[i+1]
                a[i], a[i+1] = a[i+1], a[i]
            end
        end
        i_end -= 1
        @inbounds for i in i_end:-1:i_beg+1 # i меняется в сторону уменьшения (в диапазоне шаг отрицательный)
            if a[i-1] > a[i]
                a[i-1], a[i] = a[i], a[i-1]
            end
        end
        i_beg += 1
    end
    return a
end
```

**Замечание.** Данный алгоритм может быть улучшен, если после каждого "прохода" пороверять наличие факта перестановки элементов массива при этом "проходе", и в случае отсутствия данного факта сразу завершать сортировку (см. "пузырьковую" сортировку).

Ассимптотическая сложность сортировки перемешиванием, очевидно, является такой же как и у "пузырьковой" сортировки, т.е. $O(N^2)$.

## Быстрая (O(Nlog(N)) сортировка Хоара

Визуализацию идеи быстой сортировки можно посмотреть, например, [здесь](https://ru.wikipedia.org/wiki/Быстрая_сортировка)

```julia
function quick_sort!(A)
    length(A) <= 1 &&  return A
    N = length(A)
    left, right = part_sort!(A, A[rand(1:N)]) # - "базовый" элемент массива выбирается случайнам образом
    quick_sort!(left) # передача среза по ссылке исключает лишние аллокоции (коприрования)
    quick_sort!(right)
    return A
end

function part_sort!(A, b)
    N = length(A)
    K, L, M = 0, 0, N
    #ИНВАРИАНТ: A[1:K] < b && A[K+1:L] == b && A[M+1:N] > b
    @inbounds while L < M # макрос @inbounds отменяет контроль выхода за пределы массива
        if A[L+1] == b
            L += 1
        elseif A[L+1] > b
            A[L+1], A[M] = A[M], A[L+1]
            M -= 1
        else # if A[L+1] < b
            L += 1; K += 1
            A[L], A[K] = A[K], A[L]
        end
    end
    return @view(A[1:K]), @view(A[M+1:N]) # 1:K и M+1:N - эти диапазоны индексов определяют ещё не отсортированные части массива A
end
```

**Замечание 1.** Быстрая сортировка Хоара так же может быть реализована бутем разделения массива не на 3 части, а - только на 2: в левую часть должны быть перемещены все элементы, меньшие заданногоо базового элемента, а в правую - все элементы, большие или равные ему.

Реализация этой идеи потребует изменения функции part_sort!, в которой сновной цикл может быть спроектировн на основе следующего инварианта:

```julia
    K, L = 0, N
    #ИНВАРИАНТ: A[1:K] < b && A[L+1:N] >= b
    while K < L
        ...
    end
```

**Замечание 2.** Используемую в quick_sort! вспомогательную функцию part_sort! можно немного изменить, сделав так, чтобы она возвращала не ссылки на полученные части массива (которые затем требуется отсортировать независимо друг от дуга), а два соответствующих этим чсатям массива диапазона индексов, следующим образом.

```julia
@inline function part_sort!(A, index_range::AbstractUnitRange, b)
    K, L, M = index_range[1]-1, index_range[begin]-1, index_range[end] # 0, 0, N
    #ИНВАРИАНТ: A[index_range[begin]:K] < b && A[K+1:L] == b && A[M+1:index_range[end]] > b
    @inbounds while L < M 
        if A[L+1] == b
            L += 1
        elseif A[L+1] > b
            A[L+1], A[M] = A[M], A[L+1]
            M -= 1
        else # if A[L+1] < b
            L += 1; K += 1
            A[L], A[K] = A[K], A[L]
        end
    end    
    return index_range[begin]:K, M+1:index_range[end] # - эти диапазоны индексов определяют ещё не отсортированные части массива A
end
```

Основной цикл в теле этой функции при этой её модификации не подвергся никаким изменениям.

При этом в код функции quick_sort! пришлось бы внести следующие изменения:

```julia
function quick_sort!(A, index_range=firstindex(A):lastindex(A))
    length(A) <= 1 &&  return A
    N = length(A)
    left_range, right_range = part_sort!(A, index_range, A[rand(1:N)]) # - "базовый" элемент массива выбирается случайнам образом
    quick_sort!(A, left_range) # передача среза по ссылке исключает лишние аллокоции (коприрования)
    quick_sort!(A, right_range)
    return A
end
```

Здесь в список аргументов функции пришлость добавить ещё аргумент range_index, через который в функцию можно будет передавать диапазон индексов той части массива, которую требуется отсортировать. По умолчанию этот диапазан равен диапазону всех индексов массива,поэтому данную функцию по-прежнему можно будет вызывать с одним аргументом (если требуется отсортировать весь массив целиком).

Такой вариант функции part_sort! делает её более универсальной. Так это позволит теперь использовать её не только для реализации алгоритма быстрой сортировки Хоара, но и в алгоритме Хоара быстрого вычисдения медианы массива, который будет рассмотрен далее.

### Оценка сложности алгоритма Хоара

На каждом шаге алгоритма происходит разделение массива на 3 неперерывные части: леваячасть, все элементы которой меньше выбранного базового элемента, средняя часть, все элементы которой равны базовому элементу, и правая часть, все элементы которой больше базового элемента.

Если средняя часть всегда состоит ровно из одного элемента (так будет, если в массиве нет повтряющихся элементов), то это будет соответствать наихудшему случаю. Далее, для простоты анализа среднюю чсть (состоящую из одного элемента) не будем исключать из дальнейшей сортирови, и будем ее относить, например, к правой части. Таким образом, будем считать, что на каждом шаге алшоритма происходит деление массива на две части: левую и правую, каждую из которых требуется далее отсортировать независимо друг от друга.

Для ещё большего упрощения анализа будем считать, что эти части имеют равную длину, хотя в действительности можно расчитывать лишь на приближенное равенство их длин, и то лишь в среднестатистическом смысле. Тогда процесс сортировки, каждый шаг которой приводит к делению массива на две равные части (точнее говоря, - приближенно равные, в среднестатистическом смысле). Наглядно это можно представить себе в виде двоичного дерева, корню которого соответсвует исходный массив, а каждому узлу соответствует некоторая часть массива, получающаяся делением более крупной части на две меньшие части.

Если число элементов в массиве есть некоторая степень 2, $N=2^m$, то высота такого дерева будет равна $m=log_2(N)$. Каждому ярусу этого дерева соответствует $N$ операций сравнения (грубо говоря). Поэтому весь алгоритм сортировки в этом случае потребует $N \log(N)$ операций сравнения. Т.е. его вычислительная сложность должна быть оценена как  элементарных операций (число которых в наихудшем случае пропорционально числу опраций сравнения).

Если же длина исходного массива не равна в точности некоторой степени двойки, то мы моглибы рассмотренть этот алгоритм в применении к массиву длины $N'>N$, которая есть длижайшее к $N$ натуральное число, равное некоторой степени двойки. Применительно к массиву длины $N'$ оценка сложности нами была получена. Ясно, что она не превышает сложности сортировки исходного массива длины $N$, при этом, в силу того, что $N'<2N$, имеем:

$$Сложность_сортировки_массива_длины_N <= O(N' \log(N')) <= O(2N\log(2N) = O(N\log(N))$$

## Порядковые статистики. Медиана массива

**i-ой порядковой статистикой$ - это значение i-го элемента отсортированного массива.

Порядковую статустику массива можно вычислить, не осуществляя его сортировку.

### Быстрое ($O(N)$) вычисление $i$-ой порядковой статистики

Быстое вычисление $i$-ой порядковой статистики может быть основано на вспомогательнй процедуре Хоара (названной нами ранее part_sort!). При этом, в отличие от соответствующей рекурсивной процедуры сортировки, вычисление порядковой статистики будет закончено, как только будет определен диапазон индексов соответствующий значению текущего базового элемента, содержащий заданный индекс $i$, т.е. такой, что  $K < i < M$.  В этом случае ответом, очевидно, будет $A[i]$. А пока средний диапазон, содержащий i, не найден, его поиск нужно будет продолжать только в той части массива (из двух оставшихся), в которой этот индекс содержится.

Таким образом, если при сортировке массива методом Хоара происходит как бы обход всего соответствующего двоичного дерева, то при вычислении порядковой статистики с заданнным индексом требуется только пройти по одной единственной ветке этого дерева. И для этого понадобится $N+N/2+N/4+N/8+...= O(N)$ операций сравнения.

```julia
function order_statistics!(A::AbstractVector{T}, i::Integer)::T where T
    function find(index_range)
        left_range, right_range = part_sort!(A, index_range, A[rand(index_range)]) # - "базовый" элемент массива выбирается случайным образом
        if i in left_range
            return find(left_range) 
        elseif i in right_range
            return find(right_range)
        else
            return A[i]
        end
    end
    find(firstindex(A):lastindex(A))
end

order_statistics(A, i) = order_statistics!(copy(A), i)
```

**Замечание 1.** Использование здесь варианта функции part_sort!, которая возвращала бы ссылки на соответствующие части массива было бы невозможным, т.к. индексация части массива, представленная с помощью ссылки на соответствующий срез исходного массива была бы уже другой.

**Замечание 2.** Быстрое ($O(N)$) вычисление первых (аналогично, - последних) $k$ порядковых статистик, если только $k$ не зависит от длины массива и не является слишком большим, возможно и без использования алгоритма Хоара.

Соответствующий алгоритм может выглядеть следующим образом.

```julia
function minimums(array, k)
    N = length(array)
    k_minimums = sort(array[1:k])
    i = k
    # ИНВАРИАНТ: issorted(k_mins) && k_mins - содержит k наименьших элементов в array[1:i]
    while i < length(array)
        i += 1
        if array[i] < k_minimums[end]
            k_minimums[end] = array[i]
            insert_end!(k_minimums)
        end
    end
    return k_minimums
end            

function insert_end!(array)::Nothing
    j = length(array)
    while j>1 && array[j-1] > array[j]
        array[j-1], array[j] = array[j], array[j-1]
        j -= 1
    end
end
```

### Медиана массива

**Медиана (середина) массива** - это порядковая статистика с индексом $(N+1)/2$, если длина массива $N$ - нечетная, или - среднее арифметическое порядковых статистик с индексами $N/2$ и $N/2+1$, если $N$ - четное.

Очевидно, что алгоритм Хоара дает быстрый ($O(N)$) алгоритм вычисления медианы.

## Быстрая сортировка слияниями

Быстрая сортировка слияниями осуществляется на основе следующей вспомогательной процедуры, осуществляющей слияние двух предварительно отсортирванных массивов в один отсортированный за $O(N1+N2)$, где $N1$, $N2$ - длины заданных отсортированных массивов. При этом это можно сделать без использования дополнителной памяти, что очень важно.

Сортировка слиянием базируется на следующей вспомогательной процедуре.

```julia
"""
merge!(a1, a2, a3)::Nothing

    ДАНО: length(a3) == length(a1)+length(a2) && issorted(a1) && issorted(a2)
    
    РЕЗУЛЬТАТ: issorted(a3)
"""
function Base.merge!(a1, a2, a3)::Nothing
    i1, i2, i3 = 1, 1, 1
    @inbounds while i1 <= length(a1) && i2 <= length(a2) # @inbounds - передотвращает проверки выхода за пределы массивов
        if a1[i1] < a2[i2]
            a3[i3] = a1[i1]
            i1 += 1
        else
            a3[i3] = a2[i2]
            i2 += 1
        end
        i3 += 1
    end
    if i1 > length(a1)
        a3[i3:end] .= @view(a2[i2:end]) # Если бы тут было: a3[i3:end] = @view(a2[i2:end]), то это привело бы к лишним аллокациям (к созданию промежуточного массива)
    else
        a3[i3:end] .= @view(a1[i1:end])
    end
    nothing
end
```

Собственно сортирвка слияниями может быть записаны следующим образом.

```julia
function merge_sort!(a)
    b = similar(a) # - вспомогательный массив того же размера и типа, что и массив a
    N = length(a)
    n = 1 # n - текущая длина блоков
    while n < N
        K = div(N,2n) # - число имеющихся пар блоков длины n
        for k in 0:K-1
            merge!(@view(a[(1:n).+k*2n]), @view(a[(n+1:2n).+k*2n]), @view(b[(1:2n).+k*2n]))
        end
        if N - K*2n > n # - осталось еще смержить блок длины n и более короткий остаток
            merge!(@view(a[(1:n).+K*2n]), @view(a[K*2n+n+1:end]), @view(b[K*2n+1:end]))
        elseif 0 < N - K*2n <= n # - оставшуюся короткую часть мержить не с чем
            b[K*2n+1:end] .= @view(a[K*2n+1:end])
        end
        a, b = b, a
        n *= 2
    end
    if isodd(log2(n)) # - если цикл был выполнен нечетное число раз
        b .= a  # b = copy(a) - это было бы не то же самое, т.к. тут получилась бы ссылка на новый массив, который создаст функция copy
        a = b
    end
    return a # - ссылка на исходный массив (проверить, что это так, можно с помощью ===)
end
```

### Оценка сложности алгоритма сортирвки слияниями

Алгоритму сортирови слияниями можно сопоставить двоичное дерево, визуально представляющее процесс слияний.

Если длина массива $N$ есть некоторая степень 2, то высота этого дерева будет равна $log_2(N)$. На каждом ярусе этого дерева выполняется $N$ сравнений, следователь  в этом  случае потребуется всего $N\log_2(N)$ операций сравнения.

Далее можно дословно повторить уже применявшееся ранее рассуждение.

Если длина исходного массива не равна в точности некоторой степени двойки, то мы могли бы рассмотреть этот алгоритм в применении к массиву длины $N'>N$, которая есть ближайшее к $N$ натуральное число, равное некоторой степени двойки.

Применительно к массиву длины $N'$ оценка сложности нами была получена. Ясно, что она не превышает сложности сортировки исходного массива длины $N$, при этом, в силу того, что $N'<2N$, имеем:

$$Сложность_сортировки_массива_длины_N <= O(N' \log(N')) <= O(2N\log(2N) = O(N\log(N))$$

## Быстрое возведение в степень

Пусть требуется вычислить целую неотрицательную степерь $a^n$ некоторого числа $n$ (на самом деле не обязательно числа, но и - матрицы, или многочлена, в общем, можно считать, что $а$ - это элемент какого-либо кольца).

Ясно, что это можно сделать за $O(n)$ операций умножения. Но возникает вопрос, а можно ли это сделать быстрее. Оказывается, что это всегда можно сделать за $log(n)$ операций, т.е. "быстро".

В частном случае, когда число $n$ - есть некоторая степень 2 это не вызывает вопроса. Например, вычислить $a^8$ можно всего за 3 операции умножения ($3=log_28$):

```julia
a2 = a*a
a4 = a2*a2
a8 = a4*a4
```

Или, когда $n$ есть произвольная степень двойки (целая не отрицательная), быстрый алгоритм возведения в эту степень мог бы выглядеть так:

```julia
# число n - есть некоторая целая неотрицательная степень 2
p, k = a, n
#ИНВАРИАНТ: p^k = a^n
while k != 1
    p *= p
    k ÷= 2 # k гарантированно делится на 2, т.к. по предположению n - степень 2
end
```

В случае, когда целое неотрицательное число $n$ не является степенью 2 напрямую приведенный алгоритм применить нельзя. Тут трудность будет состоять в том, что не всегда переменная $k$ будет делиться на 2.

Идея быстрого алгоритма в общем случае состоит в том, что если на некотором шаге рассмотренного выше алгоритма число k окажется нечетным, то вместо деления из него надо будет вычесть 1, а затем уже, на следующей итерации, оно гарантировано поделится на 2.

Эту идею можно реализовать следующим образом.

```julia
k, t, p = n, 1, a

#ИНВАРИАНТ: p^k*t=a^n 
while k>0
    if even(k) # k - четное
        k ÷= 2
        p *= p # т.к. p^k = (p*p)^k*(t/2)
    else
        k -= 1
        t *= p # т.к. p^k * t = p^(k-1)*(p*t)
    end   
end
#УТВ: t = a^n
```

Остается только понять, что сложность этого алгоритма попрежнему будет иметь оценку $O(\log(n))$. В самом деле, в наихудшем случае единицу придется вычитать через раз, при этом для числа повторений цикла очевидна оценка сверху $2\log_2(n)$, а это и есть $O(\log(n))$

## Эффективный алгоритм вычисления функции $log_a(x)$ с заданной точностью

Пусть требуется составить алгоритм вычисления логарифма $log_a(x)$ по некоторому основанию $a$. Для произвольного значения аргумента $x$ расчитывать на получения точного ответа, имеюя ввиду вычисления с плавающей точкой, не приходится. Поэтому задачу сформулируем так: для произвольно заданного значения аргумента $x$ и для заданной, сколь угодно малой величины абсолютной погрешности $\varepsilon>0$ найти значение $y: |\log_a(x)-y| <= \varepsilon$.

Для определенности будем считать $a>1$. Обозначим $\hat{y}=\log_a(x), \ \ \ \Delta = \hat{y}-y$, тогда

$$
x = a^{\hat{y}} = a^{y+\Delta}=a^ya^{\Delta}=a^{y}z^t
$$
где $z,t$ - новые переменные, выбором значений которых мы можем свободно распорядиться, лишь бы $a^{\Delta}=z^t$. А именно, имеем

$$
\Delta=t\log_az
$$

Откуда, исходя из требования $|\Delta|<=\varepsilon$, получаем

$$

|\Delta|=|t||\log_az|<=\varepsilon
$$

Для выполнения последнего неравенства достаточно, что бы $|t|<=\varepsilon$ и $|\log_az|<=1$. Откуда, учитывая, что $a>1$, находим явное условие для второй переменной $1/a <= z <= a$.

Т.е. если добиться того, что бы

$$
|t|<=\varepsilon, \ \ \ 1/a <= z <= a
$$

то задача будет решена, т.е. получится, что $∣\log_a(x)−y∣<=ε$

Соответствующий алгоритм выглядит следующим образом.

```julia
z, t, y = x, 1, 0
#ИНВАРИАНТ: a^y * z^t == x (=const)
while z > a || z < 1/a || t > ε   
    if z > a
        z /= a
        y += t # т.к. z^t = (z/a)^t * a^t
    elseif z < 1/a
        z *= a
        y -= t # т.к. z^t = (z*a)^t * a^-t
    else # t > ε
        t /= 2
        z *= z # т.к. z^t = (z*z)^(t/2)
    end
end
#УТВ: y: |log_a(x)-y| <= ε
```

**Замечание.** Если в этом алгритме изменить порядок проверки условий в теле цикла, сделав первой проверку условия t > ε, то это приведет к зацикливанию (почему?).

## Решение нелинейного уравнения методом деления отрезка пополам

Рассмотрим уравнение вида
$$f(x)=0,$$
где $f:\ [a;b]\to \mathbb{R}$ - некоторая непрерывная на отрезке $[a;b]$ функция, и при этом выполнены следующие два условия:

на открытом интервале $(a;b)$ уравнение имеет ровно один корень (этот интервал называют интервалом локализации корня);
на концах $[a;b]$ значения функции имеют противоположные знаки, т.е. $f(a)\cdot f(b)<0$.
Пусть задана максимально допустимая абсолютная погрешность $\varepsilon>0$, с которой требуется вычислить значение корня. Тогда задача сводится к тому, чтобы найти такой отрезок $[a^\prime; b^\prime]$, чтобы, во-первых, он содержал корень, и, во-вторых, его длина не превосходила бы величины $\varepsilon$. Тогда любую точку этого отрезка, например, его середину, можно принять за искомое приближенное решение уравнения.

Идея метода деления отрезка пополам для приближенного решения данного уравнения выражается в следующих пунктах:

- вычислить функцию в средне отрезка локализации корня;
- сравнивать знак полученного значения со знаком функции в одном из концов отрезка локализации, например, со значением на левом его конце;
- если знаки окажутся совпадающими, то левую половину отрезка локализации можно смело отбросить (там заведомо корня нет) и переместить левую границу отрезка локализации в среднюю его точку;
- если же знаки окажутся противоположными, то, наоборот, правую половину отрезка следует отбросить (т.к. корень только один), и правую границу отрезка локализации переместить на его середину.

Перечисленные пункы следует повторять до тех пор, пока длина отрезка локализации превышает заданую максимально допустимую погрешность.

Таким образом, если переменные $a$, $b$ считать фазовыми переменными цикла (изменяющимися в этом цикле), то условие $f(a)\cdot f(b)<0$ должно рассматриваться как его инвариант. При этом условие $b-a>\varepsilon$ есть условие продолжения цикла.

Соответствующая функция на языке Julia могла бы выглядеть так:

```julia
function bisect(f::Funcnion, a, b, ε)
    y_a=f(a)
    # ИНВАРИАНТ: f(a)*f(b) < 0 (т.е. (a,b) - содержит корень)
    while b-a > ε
        x_m = (a+b)/2
        y_m=f(x_m)
        if y_m==0
            return x_m
        end
        if y_m*y_a > 0 
            a=x_m
        else
            b=x_m
        end
    end
    return (a+b)/2
end
```

Вычислительная сложность рассмотренного алгоритма оценивается, очевидно, как $O(log((b-a)/\varepsilon)$, при $\varepsilon \to 0$.

## Наибольший общий делитель (НОД). Алгоритм Евклида

Пусть a, b - целые числа.

Их наибольший общий делитель, НОД(a,b) - это наибольшее положительное целое, являющееся делителем обоих чисел.

При этом дополнительно считается, что НОД(0,0)=0.

Ясно что,

- $\forall a,b \in \mathbb{Z} \ \ НОД(a,b) = НОД(b,a)$
- $\forall a \in \mathbb{Z} \ \  НОД(a,1)=1$
- $\forall a \in \mathbb{Z} \ \ НОД(a,0)=a$
- $\forall a,b \in \mathbb{Z} \ \ НОД(a,b) = НОД(a, -b)$
- $\forall a,b \in \mathbb{Z} \ \ НОД(a,b) = НОД(a,a+b) = НОД(a, a-b)$

### Алгоритм Евклида

```julia
# m, n - заданные целые
a, b = m, n
#ИНВАРИАНТ: НОД(a,b)==НОД(m,n)
while b != 0
    a, b = b, a % b # a % b - целочисленный остаток от деления a на b
end
#УТВ: b == НОД(m,m)
```

**Замечание.** В этом варианте алгоритма, если не ограничиваться только положителными a, b, ответ может получиться отрицательным, что легко поправить, взяв абсолютную величину.

### Расширенный алгоритм Евклида

**Теорема.** $\forall a,b \in \mathbb{Z}$ $\exist u,v \in \mathbb{Z}$, такие что $НОД(a,b) = ua + vb$.

Мы докажем эту теорему, спроектировав соответствующий алгоритм, основываясь на методе инварианта цикла.

Алгоритм, подобный алгоритму Евклида, который наряду с $НОД(a,b)$ вычисляет также и названные целые числа $u,v$, называется **расширенным алгоритмом Евклида**.

Для проектирования этого алгоритма применим метод инварианта цикла.

```julia
# m, n - заданные целые
a, b = m, n
u_a, v_a = 1, 0
u_b, v_b = 0, 1
#=
ИНВАРИАНТ: 
    НОД(m,n)==НОД(a,b)
    a = u_a*m + v_a*n 
    b = u_b*m + v_b*n
=#

while b != 0
    k = a÷b
    a, b = b, a % b 
    #УТВ: a % b = a-k*b - остаток от деления a на b
    u, v = u_a, v_a
    u_a, v_a = u_b, u_a
    u_b, v_b = u-k*u_b, v-k*v_b
end
#УТВ: b == НОД(m,m) == u_a*m + v_a*n
```

Алгорит построен, тем самым теорема доказана.

**Замечание 1.** На каждом шаге расширенного алгоритма Евклида требуется вычислять частное и остаток от деления целых чисел. Однако в языке Julia имеется встроенная функци divrem позволяющая получать и частное и остаток всего за одну операцию. С использование этой функции следующие строчки кода с двумя операциями % и ÷

```julia
k = a÷b
a, b = b, a % b 
```

могут быть заменены на код с одной единственной операцией divrem следущим образом:

```julia
k, r = divrem(a,b)
a, b = b, r
```

что является предпочтительным.

**Замечание 2.** В приведенном варианте расширеннного алгоротитма Евклида, также как и в рассмотренном выше простом алгоритме Евклида, не учтена возможность отрицательных значений чисел a, b. Но это очень легко поправить, только теперь, если понадобится изменять знак полученного наибольшего (по модулю) общего делителя с отрицательного на положительный, одновременно с этим должны изменияться знаки и коэффициентов u_a, v_a.

### Вычисление обратного элемента в кольце вычетов по модулю $n$

Практическая важность расширенного алгоритма Евклида состоит в том, что с его помощью можно находить обратные элементы в кольце вычетов по модулю $n$.

Как известно, элемент $m$ обратим в кольце вычетов по модулю $n$, если числа $m$, $n$ взаимно простые, т.е. если $НОД(m,n)=1$.

Таким образом, если $НОД(m,n) = um + vn,$ и если $НОД(m,n)=1$, то $um + vn=1,$ или $um\equiv 1 (mod\ n),$ т.е. если $m \in \mathbb{Z_n}$, то

$$m^{-1} = u (mod\ n)$$

**Замечание.** В языке Julia имеются встроенные функции gcd, gcdx, реализующие алгоритм Евклида и расширенный алгоритм Евклида, соответственно.

Также для работы с алгебраическими структурами, включая и кольцо вычетов целых чисел, у Julia имеется отдельный обширный пакет AbstractAlgebra (требующий предварительной установки и изучения).